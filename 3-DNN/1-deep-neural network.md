## 前言
深度學習是一種機器學習的方法，藉由模仿人類大腦神經元的結構，定義並找出解決問題的函式。所謂深度學習是一種具有多層的神經網路(Neural Network, NN)，我們又稱深度神經網路（Deep Neural Network, DNN)，在神經網路的階層上，一般包括輸入層、隱藏層與輸出層，而中間的隱藏層可以有一層以上。每一個類神經網路都會形成一個函數集，並且夠過透過反向傳播和梯度下降的優化方法不斷的收斂錯誤，達到學習的效果。所謂的反向傳播經由反覆的測試與計算損失，讓神經網路的各層根據計算到的正確答案，調整出不同特徵值的權重。此外每一個神經元都是一個激勵函數，常見的激勵函數有：Sigmoid、tanh以及ReLU ，激勵函數主要的功用是利用非線性方程式，解決非線性問題。在神經網路中激勵函數需選擇可微分的函數，因為在進行深度網路學習時反向傳遞需要進行一次微分計算，並使用梯度下降的方式逐漸逼近真實答案。







對使用反向傳播訓練的類神經網絡來說，梯度的問題是最重要的，使用 sigmoid 和 tanh 函數容易發生梯度消失問題，是類神經網絡加深時主要的訓練障礙。Relu會使部分神經元的輸出為0，可以讓神經網路變得稀疏，緩解過度擬合的問題。