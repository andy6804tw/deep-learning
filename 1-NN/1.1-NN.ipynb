{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import  math\n",
    "\n",
    "# x1=np.array([0.05])\n",
    "# x2=np.array([0.1])\n",
    "x=[0.05,0.1]\n",
    "# y1=np.array([0.01])\n",
    "# y2=np.array([0.99])\n",
    "y=[0.01, 0.99]\n",
    "\n",
    "layer1=np.zeros(2) # H\n",
    "layer2=np.zeros(2)\n",
    "layer1_weight = [0.15, 0.2, 0.25, 0.3]\n",
    "layer2_weight = [0.4, 0.45, 0.5, 0.55]\n",
    "bias=[0.35, 0.6]\n",
    "learnRate=0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(H):\n",
    "    return 1/(1+math.pow(math.e,-H))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward Pass\n",
    "## First layer\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        layer1[i] += (x[j]*layer1_weight[(i*2)+j])\n",
    "        \n",
    "### calc first layer active function\n",
    "for i in range(2):\n",
    "    layer1[i]=sigmoid(layer1[i]+bias[0])\n",
    "    \n",
    "## Second layer\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        layer2[i] += (layer1[j]*layer2_weight[(i*2)+j])\n",
    "### calc second layer active function\n",
    "for i in range(2):\n",
    "    layer2[i]=sigmoid(layer2[i]+bias[1])\n",
    "    \n",
    "## calculating error\n",
    "eTotal=(0.5*math.pow(layer2[0]-y[0],2))+(0.5*math.pow(layer2[1]-y[1],2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partial_y1 = layer2[0]*(1-layer2[0])*(y[0]-layer2[0])\n",
    "# partial_y2 = layer2[1]*(1-layer2[1])*(y[1]-layer2[1])\n",
    "# partial_h1 = layer1[0]*(1-layer1[0])*((patrial_y1*layer2_weight[0])+(patrial_y2*layer2_weight[2]))\n",
    "# partial_h2 = layer1[1]*(1-layer1[1])*((patrial_y1*layer2_weight[1])+(patrial_y2*layer2_weight[3]))\n",
    "partial_layer2 = [layer2[0]*(1-layer2[0])*(y[0]-layer2[0]), layer2[1]*(1-layer2[1])*(y[1]-layer2[1])]\n",
    "partial_layer1 = [layer1[0]*(1-layer1[0])*((partial_layer2[0]*layer2_weight[0])+(partial_layer2[1]*layer2_weight[2])), layer1[1]*(1-layer1[1])*((partial_layer2[0]*layer2_weight[1])+(partial_layer2[1]*layer2_weight[3]))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bbackward\n",
    "## Second layer\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        layer2_weight[(i*2)+j]+=learnRate*partial_layer2[i]*layer1[j]\n",
    "## First layer\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        layer1_weight[(i*2)+j]+=learnRate*partial_layer1[i]*x[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14786331286301752\n",
      "[0.54893723 0.91738262]\n",
      "[0.01, 0.99]\n"
     ]
    }
   ],
   "source": [
    "print(eTotal)\n",
    "print(layer2)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2983711087600027\n",
      "[0.75136507 0.77292847]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.3750587095120251\n",
      "[0.8709711  0.89594588]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.38198919297694856\n",
      "[0.88034727 0.90953868]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.37816798090776976\n",
      "[0.87611363 0.91136701]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.3726094488011731\n",
      "[0.8697189  0.91188276]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.3663989880593418\n",
      "[0.86249592 0.91222677]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.35964262731565555\n",
      "[0.85456237 0.91254249]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.3523145950588332\n",
      "[0.84586913 0.91285088]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.3443684403317772\n",
      "[0.83633636 0.91315538]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.33575413141329585\n",
      "[0.82587338 0.91345664]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.32642250213466023\n",
      "[0.81438279 0.91375484]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.31632854263104965\n",
      "[0.80176303 0.91405006]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.3054354403690515\n",
      "[0.78791182 0.91434237]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.29371978641867624\n",
      "[0.77273142 0.91463184]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.28117799270534344\n",
      "[0.75613589 0.91491854]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.2678336670579333\n",
      "[0.7380609  0.91520251]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.2537452822677203\n",
      "[0.71847576 0.91548383]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.23901295068058934\n",
      "[0.69739705 0.91576255]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.22378258550697253\n",
      "[0.67490217 0.91603873]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.20824542441239263\n",
      "[0.65114038 0.91631239]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.19263112770890464\n",
      "[0.6263378  0.91658359]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.17719370576748783\n",
      "[0.60079339 0.91685234]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.16219134878684438\n",
      "[0.57486371 0.91711868]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.14786331286301752\n",
      "[0.54893723 0.91738262]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.1344084475776345\n",
      "[0.52340192 0.91764417]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.12196989320886656\n",
      "[0.49861218 0.91790334]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.11062876440423065\n",
      "[0.47486187 0.91816013]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.10040699902398648\n",
      "[0.45236808 0.91841456]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.09127717912585182\n",
      "[0.43126703 0.91866664]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.08317593401076204\n",
      "[0.41162045 0.91891638]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.0760176749625078\n",
      "[0.39342872 0.9191638 ]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.06970641690984176\n",
      "[0.37664661 0.91940893]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.06414465826429812\n",
      "[0.36119859 0.9196518 ]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.05923925258466624\n",
      "[0.34699174 0.91989242]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.0549047533165955\n",
      "[0.33392562 0.92013084]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.05106490098085657\n",
      "[0.32189911 0.92036707]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.047652887375929986\n",
      "[0.31081485 0.92060116]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.04461089922015284\n",
      "[0.30058173 0.92083313]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.04188929501015192\n",
      "[0.29111614 0.92106302]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.039445642252887526\n",
      "[0.28234232 0.92129085]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.03724374873728802\n",
      "[0.27419222 0.92151666]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.03525275870683297\n",
      "[0.26660506 0.92174048]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.03344634560896833\n",
      "[0.25952669 0.92196233]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.03180201027137815\n",
      "[0.25290898 0.92218225]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.03030048107045606\n",
      "[0.24670918 0.92240027]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.028925206785760778\n",
      "[0.24088929 0.9226164 ]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.02766193065982812\n",
      "[0.2354155  0.92283069]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.026498334012107577\n",
      "[0.23025769 0.92304316]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.025423738578646403\n",
      "[0.22538901 0.92325383]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.024428857987550595\n",
      "[0.22078545 0.92346272]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.023505590119509027\n",
      "[0.21642552 0.92366988]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.022646843382952357\n",
      "[0.21228992 0.92387531]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.021846391083082256\n",
      "[0.20836131 0.92407904]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.02109874905961365\n",
      "[0.20462406 0.92428111]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.020399072611123843\n",
      "[0.20106406 0.92448152]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.019743069427596537\n",
      "[0.19766853 0.9246803 ]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.019126925834721642\n",
      "[0.19442589 0.92487748]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.018547244132017672\n",
      "[0.19132563 0.92507308]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.018000989198912788\n",
      "[0.18835816 0.92526712]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.017485442863582966\n",
      "[0.18551474 0.92545961]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.016998164791448243\n",
      "[0.18278739 0.92565058]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.016536958864524012\n",
      "[0.1801688  0.92584006]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.01609984419819516\n",
      "[0.17765225 0.92602805]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.015685030085701948\n",
      "[0.17523159 0.92621458]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.015290894278616272\n",
      "[0.17290115 0.92639966]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.014915964108652905\n",
      "[0.1706557  0.92658333]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.014558900036189287\n",
      "[0.16849041 0.92676558]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.014218481277008517\n",
      "[0.16640081 0.92694645]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.013893593213576631\n",
      "[0.16438277 0.92712595]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.013583216342681101\n",
      "[0.16243247 0.9273041 ]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.013286416549159265\n",
      "[0.16054633 0.92748091]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.013002336527090264\n",
      "[0.15872104 0.9276564 ]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.012730188196313993\n",
      "[0.15695353 0.92783058]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.012469245984370811\n",
      "[0.15524092 0.92800348]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.01221884086266232\n",
      "[0.15358052 0.92817511]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.011978355041411174\n",
      "[0.15196982 0.92834548]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.011747217241342377\n",
      "[0.15040649 0.92851461]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.011524898471320206\n",
      "[0.14888831 0.92868252]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.011310908250788211\n",
      "[0.14741324 0.92884921]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.011104791224048366\n",
      "[0.14597932 0.92901471]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.01090612412040808\n",
      "[0.14458476 0.92917902]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.010714513020207029\n",
      "[0.14322783 0.92934217]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.010529590891868536\n",
      "[0.14190692 0.92950416]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.010351015369531976\n",
      "[0.14062052 0.92966501]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.010178466744623658\n",
      "[0.13936719 0.92982473]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.010011646148004668\n",
      "[0.13814559 0.92998334]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.009850273902172309\n",
      "[0.13695444 0.93014084]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.009694088025452508\n",
      "[0.13579252 0.93029726]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.009542842872257056\n",
      "[0.1346587 0.9304526]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.009396307895339075\n",
      "[0.1335519  0.93060687]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.009254266517601199\n",
      "[0.13247108 0.93076009]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.009116515102426824\n",
      "[0.13141528 0.93091227]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.008982862012743793\n",
      "[0.13038357 0.93106342]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.008853126750115377\n",
      "[0.12937507 0.93121355]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.008727139166107616\n",
      "[0.12838895 0.93136268]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.008604738739019952\n",
      "[0.12742441 0.93151081]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.008485773909805105\n",
      "[0.1264807  0.93165795]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.008370101471656264\n",
      "[0.1255571  0.93180412]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.00825758600831513\n",
      "[0.12465292 0.93194933]\n",
      "[0.01, 0.99]\n",
      "---------\n",
      "0.008148099376664605\n",
      "[0.12376751 0.93209359]\n",
      "[0.01, 0.99]\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import  math\n",
    "\n",
    "# x1=np.array([0.05])\n",
    "# x2=np.array([0.1])\n",
    "x=[0.05,0.1]\n",
    "# y1=np.array([0.01])\n",
    "# y2=np.array([0.99])\n",
    "y=[0.01, 0.99]\n",
    "\n",
    "layer1=np.zeros(2) # H\n",
    "layer2=np.zeros(2)\n",
    "layer1_weight = [0.15, 0.2, 0.25, 0.3]\n",
    "layer2_weight = [0.4, 0.45, 0.5, 0.55]\n",
    "bias=[0.35, 0.6]\n",
    "learnRate=0.5\n",
    "\n",
    "for echo in range(100):\n",
    "    # Forward Pass\n",
    "    ## First layer\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            layer1[i] += (x[j]*layer1_weight[(i*2)+j])\n",
    "\n",
    "    ### calc first layer active function\n",
    "    for i in range(2):\n",
    "        layer1[i]=sigmoid(layer1[i]+bias[0])\n",
    "\n",
    "    ## Second layer\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            layer2[i] += (layer1[j]*layer2_weight[(i*2)+j])\n",
    "    ### calc second layer active function\n",
    "    for i in range(2):\n",
    "        layer2[i]=sigmoid(layer2[i]+bias[1])\n",
    "\n",
    "    ## calculating error\n",
    "    eTotal=(0.5*math.pow(layer2[0]-y[0],2))+(0.5*math.pow(layer2[1]-y[1],2))\n",
    "\n",
    "    partial_layer2 = [layer2[0]*(1-layer2[0])*(y[0]-layer2[0]), layer2[1]*(1-layer2[1])*(y[1]-layer2[1])]\n",
    "    partial_layer1 = [layer1[0]*(1-layer1[0])*((partial_layer2[0]*layer2_weight[0])+(partial_layer2[1]*layer2_weight[2])), layer1[1]*(1-layer1[1])*((partial_layer2[0]*layer2_weight[1])+(partial_layer2[1]*layer2_weight[3]))]\n",
    "\n",
    "    # Bbackward\n",
    "    ## Second layer\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            layer2_weight[(i*2)+j]+=learnRate*partial_layer2[i]*layer1[j]\n",
    "    ## First layer\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            layer1_weight[(i*2)+j]+=learnRate*partial_layer1[i]*x[j]\n",
    "\n",
    "    print(eTotal)\n",
    "    print(layer2)\n",
    "    print(y)\n",
    "    print(\"---------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
