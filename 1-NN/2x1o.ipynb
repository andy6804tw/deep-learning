{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import string\n",
    "\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate a random number where:  a <= rand < b\n",
    "def rand(a, b):\n",
    "    return (b-a)*random.random() + a\n",
    "\n",
    "# Make a matrix (we could use NumPy to speed this up)\n",
    "def makeMatrix(I, J, fill=0.0):\n",
    "    m = []\n",
    "    for i in range(I):\n",
    "        m.append([fill]*J)\n",
    "    return m\n",
    "\n",
    "# our sigmoid function, tanh is a little nicer than the standard 1/(1+e^-x)\n",
    "def sigmoid(x):\n",
    "    return math.tanh(x)\n",
    "#     return 1/(1+math.pow(math.e,-x))\n",
    "\n",
    "# derivative of our sigmoid function, in terms of the output (i.e. y)\n",
    "def dsigmoid(y):\n",
    "    return 1.0 - y**2\n",
    "#     return y*(1-y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN:\n",
    "    def __init__(self, ni, nh, no):\n",
    "        # number of input, hidden, and output nodes\n",
    "        self.ni = ni + 1 # +1 for bias node\n",
    "        self.nh = nh\n",
    "        self.no = no\n",
    "\n",
    "        # activations for nodes\n",
    "        self.ai = [1.0]*self.ni\n",
    "        self.ah = [1.0]*self.nh\n",
    "        self.ao = [1.0]*self.no\n",
    "        \n",
    "        # create weights\n",
    "#         self.wi = [[0.15,0.25],[0.2,0.3],[0.5,0.5]]\n",
    "#         self.wo = [[0.4], [0.5]]\n",
    "        self.wi = makeMatrix(self.ni, self.nh)\n",
    "        self.wo = makeMatrix(self.nh, self.no)\n",
    "        # set them to random vaules\n",
    "        for i in range(self.ni):\n",
    "            for j in range(self.nh):\n",
    "                self.wi[i][j] = rand(-0.2, 0.2)\n",
    "        for j in range(self.nh):\n",
    "            for k in range(self.no):\n",
    "                self.wo[j][k] = rand(-2.0, 2.0)\n",
    "        \n",
    "        # last change in weights for momentum   \n",
    "        self.ci = makeMatrix(self.ni, self.nh)\n",
    "        self.co = makeMatrix(self.nh, self.no)\n",
    "    \n",
    "    ## 計算網路的輸出的函數\n",
    "    def update(self, inputs):\n",
    "        if len(inputs) != self.ni-1:\n",
    "            raise ValueError('wrong number of inputs')\n",
    "\n",
    "        # input activations\n",
    "        for i in range(self.ni-1):\n",
    "            self.ai[i] = inputs[i]\n",
    "\n",
    "        # hidden activations 計算隱藏層輸出值\n",
    "        for j in range(self.nh):\n",
    "            sum = 0.0\n",
    "            for i in range(self.ni):\n",
    "                sum = sum + self.ai[i] * self.wi[i][j]\n",
    "            self.ah[j] = sigmoid(sum)\n",
    "#             print('H',j+1,': ',self.ah[j])\n",
    "\n",
    "        # output activations 計算輸出層輸出值 \n",
    "        for k in range(self.no):\n",
    "            sum = 0.0\n",
    "            for j in range(self.nh):\n",
    "                sum = sum + self.ah[j] * self.wo[j][k]\n",
    "            self.ao[k] = sigmoid(sum)\n",
    "#             print('y',j+1,': ',self.ao[k])\n",
    "\n",
    "        return self.ao[:]\n",
    "    \n",
    "    ## backPropagate()：反傳遞學習的函數\n",
    "    def backPropagate(self, targets, N, M):\n",
    "        if len(targets) != self.no:\n",
    "            raise ValueError('wrong number of target values')\n",
    "\n",
    "        # calculate error terms for output\n",
    "        output_deltas = [0.0] * self.no\n",
    "        for k in range(self.no):\n",
    "#             error = targets[k]-self.ao[k]\n",
    "            error=(targets[k]-self.ao[k])\n",
    "            output_deltas[k] = dsigmoid(self.ao[k]) * error\n",
    "\n",
    "        # calculate error terms for hidden\n",
    "        hidden_deltas = [0.0] * self.nh\n",
    "        for j in range(self.nh):\n",
    "            error = 0.0\n",
    "            for k in range(self.no):\n",
    "                error = error + output_deltas[k]*self.wo[j][k]\n",
    "            hidden_deltas[j] = dsigmoid(self.ah[j]) * error\n",
    "\n",
    "        # update output weights\n",
    "        for j in range(self.nh):\n",
    "            for k in range(self.no):\n",
    "                change = output_deltas[k]*self.ah[j]\n",
    "                self.wo[j][k] = self.wo[j][k] + N*change + M*self.co[j][k]\n",
    "                self.co[j][k] = change\n",
    "\n",
    "        # update input weights\n",
    "        for i in range(self.ni):\n",
    "            for j in range(self.nh):\n",
    "                change = hidden_deltas[j]*self.ai[i]\n",
    "                self.wi[i][j] = self.wi[i][j] + N*change + M*self.ci[i][j]\n",
    "                self.ci[i][j] = change\n",
    "\n",
    "        # calculate error\n",
    "        error = 0.0\n",
    "#         for k in range(len(targets)):\n",
    "#             error = error + 0.5*(targets[k]-self.ao[k])**2\n",
    "#         return error\n",
    "        for k in range(len(targets)):\n",
    "            error = error + (targets[k]-self.ao[k])**2\n",
    "        return error/self.no\n",
    "    \n",
    "    def test(self, patterns):\n",
    "        pred=[]\n",
    "        for p in patterns:\n",
    "            print(p[0], '-> predict:', self.update(p[0]),' true:',p[1])\n",
    "            pred.append(self.update(p[0])[0])\n",
    "        return pred\n",
    "\n",
    "    def weights(self):\n",
    "        print('Input weights:')\n",
    "        for i in range(self.ni):\n",
    "            print(self.wi[i])\n",
    "        print()\n",
    "        print('Output weights:')\n",
    "        for j in range(self.nh):\n",
    "            print(self.wo[j])\n",
    "\n",
    "    def train(self, patterns, iterations=1000, N=0.5, M=0.1):\n",
    "        # N: learning rate\n",
    "        # M: momentum factor\n",
    "        for i in range(iterations):\n",
    "            error = 0.0\n",
    "            for p in patterns:\n",
    "                inputs = p[0]\n",
    "                targets = p[1]\n",
    "                self.update(inputs)\n",
    "                error = error + self.backPropagate(targets, N, M)\n",
    "            if i % 100 == 0:\n",
    "                print('error %-.5f' % error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# generate random data-set\n",
    "np.random.seed(0)\n",
    "noise = np.random.rand(100, 1)\n",
    "rng = np.random.RandomState(1)\n",
    "X = rng.rand(100, 2)\n",
    "Y = 0.5 + np.dot(X, [1.5, -1.])\n",
    "learnData=[]\n",
    "for i in range(100):\n",
    "    learnData.append([X[i],[Y[i]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input weights:\n",
      "[0.13776874061001926, 0.10318176117612099, -0.031771367667662004]\n",
      "[-0.09643329988281467, 0.004509888547443414, -0.03802634501983429]\n",
      "[0.11351943561390904, -0.07867490956842903, -0.009361218339057675]\n",
      "\n",
      "Output weights:\n",
      "[0.3335281578201248]\n",
      "[1.6324515407813407]\n",
      "[0.018747423269561025]\n",
      "error 13.48742\n",
      "error 3.51157\n",
      "error 3.51579\n",
      "error 3.49516\n",
      "error 3.47081\n",
      "error 3.45425\n",
      "error 3.44531\n",
      "error 3.44068\n",
      "error 3.43824\n",
      "error 3.43684\n",
      "error 3.43591\n",
      "error 3.43517\n",
      "error 3.43451\n",
      "error 3.43387\n",
      "error 3.43324\n",
      "error 3.43262\n",
      "error 3.43202\n",
      "error 3.43144\n",
      "error 3.43090\n",
      "error 3.43039\n",
      "error 3.42993\n",
      "error 3.42951\n",
      "error 3.42913\n",
      "error 3.42878\n",
      "error 3.42847\n",
      "error 3.42819\n",
      "error 3.42794\n",
      "error 3.42771\n",
      "error 3.42750\n",
      "error 3.42731\n",
      "error 3.42713\n",
      "error 3.42697\n",
      "error 3.42682\n",
      "error 3.42669\n",
      "error 3.42657\n",
      "error 3.42645\n",
      "error 3.42635\n",
      "error 3.42626\n",
      "error 3.42617\n",
      "error 3.42609\n",
      "error 3.42602\n",
      "error 3.42595\n",
      "error 3.42589\n",
      "error 3.42583\n",
      "error 3.42578\n",
      "error 3.42574\n",
      "error 3.42569\n",
      "error 3.42565\n",
      "error 3.42561\n",
      "error 3.42558\n",
      "error 3.42555\n",
      "error 3.42552\n",
      "error 3.42549\n",
      "error 3.42547\n",
      "error 3.42544\n",
      "error 3.42542\n",
      "error 3.42540\n",
      "error 3.42538\n",
      "error 3.42536\n",
      "error 3.42534\n",
      "error 3.42533\n",
      "error 3.42531\n",
      "error 3.42530\n",
      "error 3.42528\n",
      "error 3.42527\n",
      "error 3.42526\n",
      "error 3.42524\n",
      "error 3.42523\n",
      "error 3.42522\n",
      "error 3.42521\n",
      "error 3.42520\n",
      "error 3.42519\n",
      "error 3.42518\n",
      "error 3.42517\n",
      "error 3.42516\n",
      "error 3.42515\n",
      "error 3.42514\n",
      "error 3.42513\n",
      "error 3.42512\n",
      "error 3.42511\n",
      "error 3.42510\n",
      "error 3.42509\n",
      "error 3.42508\n",
      "error 3.42507\n",
      "error 3.42506\n",
      "error 3.42505\n",
      "error 3.42504\n",
      "error 3.42503\n",
      "error 3.42503\n",
      "error 3.42502\n",
      "error 3.42501\n",
      "error 3.42500\n",
      "error 3.42499\n",
      "error 3.42498\n",
      "error 3.42497\n",
      "error 3.42497\n",
      "error 3.42496\n",
      "error 3.42495\n",
      "error 3.42494\n",
      "error 3.42493\n",
      "Input weights:\n",
      "[1.6264449590658865, 7.253367011925798, -2.215074870235114]\n",
      "[-1.0694357507986985, -4.810157770789781, 1.4867416073023372]\n",
      "[2.410576024170299, -3.3313789928914708, 0.18482027691553687]\n",
      "\n",
      "Output weights:\n",
      "[5.119825316120907]\n",
      "[4.3637538480655955]\n",
      "[-0.7202178971186094]\n",
      "[0.417022   0.72032449] -> predict: [0.4067780526907143]  true: [0.40520851361170285]\n",
      "[1.14374817e-04 3.02332573e-01] -> predict: [0.19514664624715128]  true: [0.19783898959417756]\n",
      "[0.14675589 0.09233859] -> predict: [0.6258781121680521]  true: [0.6277952414568717]\n",
      "[0.18626021 0.34556073] -> predict: [0.4366660145868872]  true: [0.4338295900234586]\n",
      "[0.39676747 0.53881673] -> predict: [0.5564230365760745]  true: [0.556334477342648]\n",
      "[0.41919451 0.6852195 ] -> predict: [0.4454206545695186]  true: [0.44357227120818277]\n",
      "[0.20445225 0.87811744] -> predict: [-0.07350188134698929]  true: [-0.07143906179366932]\n",
      "[0.02738759 0.67046751] -> predict: [-0.1321526110488855]  true: [-0.12938612038151298]\n",
      "[0.4173048  0.55868983] -> predict: [0.5668885476341313]  true: [0.5672673751049387]\n",
      "[0.14038694 0.19810149] -> predict: [0.5149265170246144]  true: [0.5124789188079719]\n",
      "[0.80074457 0.96826158] -> predict: [0.7280783582524261]  true: [0.7328552772939074]\n",
      "[0.31342418 0.69232262] -> predict: [0.27682069268393505]  true: [0.2778136515695502]\n",
      "[0.87638915 0.89460666] -> predict: [0.9278111215908333]  true: [0.91997706494021]\n",
      "[0.08504421 0.03905478] -> predict: [0.5885889933281986]  true: [0.5885115338217846]\n",
      "[0.16983042 0.8781425 ] -> predict: [-0.12491392345709867]  true: [-0.12339687408255973]\n",
      "[0.09834683 0.42110763] -> predict: [0.224395463341069]  true: [0.22641262574452298]\n",
      "[0.95788953 0.53316528] -> predict: [0.9999999755983042]  true: [1.4036690102527358]\n",
      "[0.69187711 0.31551563] -> predict: [0.9999938144349155]  true: [1.222300039919647]\n",
      "[0.68650093 0.83462567] -> predict: [0.6899843907935512]  true: [0.6951257196250026]\n",
      "[0.01828828 0.75014431] -> predict: [-0.22553835757622756]  true: [-0.22271189892867982]\n",
      "[0.98886109 0.74816565] -> predict: [0.9999966810518478]  true: [1.2351259789799027]\n",
      "[0.28044399 0.78927933] -> predict: [0.12768806820154702]  true: [0.13138665964511925]\n",
      "[0.10322601 0.44789353] -> predict: [0.2044147032307634]  true: [0.20694548369055787]\n",
      "[0.9085955  0.29361415] -> predict: [0.9999999949636958]  true: [1.569279106265964]\n",
      "[0.28777534 0.13002857] -> predict: [0.8001044662412385]  true: [0.8016344357612455]\n",
      "[0.01936696 0.67883553] -> predict: [-0.15249011301313947]  true: [-0.14978509613444535]\n",
      "[0.21162812 0.26554666] -> predict: [0.552912075396171]  true: [0.5518955146278623]\n",
      "[0.49157316 0.05336255] -> predict: [0.9999659930802829]  true: [1.183997193803427]\n",
      "[0.57411761 0.14672857] -> predict: [0.9999910560625717]  true: [1.2144478333322093]\n",
      "[0.58930554 0.69975836] -> predict: [0.6793244166167595]  true: [0.6841999453339952]\n",
      "[0.10233443 0.41405599] -> predict: [0.23778977681738486]  true: [0.23944565542217044]\n",
      "[0.69440016 0.41417927] -> predict: [0.9996548706572921]  true: [1.127420967064715]\n",
      "[0.04995346 0.53589641] -> predict: [0.0347171519285619]  true: [0.03903378250361916]\n",
      "[0.66379465 0.51488911] -> predict: [0.9718284095139735]  true: [0.9808028557713746]\n",
      "[0.94459476 0.58655504] -> predict: [0.9999998762537443]  true: [1.3303370934842271]\n",
      "[0.90340192 0.1374747 ] -> predict: [0.9999999965633564]  true: [1.7176281687855877]\n",
      "[0.13927635 0.80739129] -> predict: [-0.10061228102142154]  true: [-0.09847676783338599]\n",
      "[0.39767684 0.1653542 ] -> predict: [0.9353485895059392]  true: [0.9311610583613676]\n",
      "[0.92750858 0.34776586] -> predict: [0.9999999942736018]  true: [1.5434970108485442]\n",
      "[0.7508121  0.72599799] -> predict: [0.9081878981590502]  true: [0.9002201693537819]\n",
      "[0.88330609 0.62367221] -> predict: [0.9999857826784111]  true: [1.201286929753106]\n",
      "[0.75094243 0.34889834] -> predict: [0.9999993042528379]  true: [1.2775153090631632]\n",
      "[0.26992789 0.89588622] -> predict: [0.005946673460153003]  true: [0.009005619451472269]\n",
      "[0.42809119 0.96484005] -> predict: [0.17408010979361963]  true: [0.1772967376585568]\n",
      "[0.6634415  0.62169572] -> predict: [0.8799272836548174]  true: [0.8734665265185504]\n",
      "[0.11474597 0.94948926] -> predict: [-0.27976808685044185]  true: [-0.2773702992770084]\n",
      "[0.44991213 0.57838961] -> predict: [0.5948563194583002]  true: [0.596478585832779]\n",
      "[0.4081368  0.23702698] -> predict: [0.8805129653515533]  true: [0.875178223898894]\n",
      "[0.90337952 0.57367949] -> predict: [0.9999994177881673]  true: [1.2813897941710948]\n",
      "[0.00287033 0.61714491] -> predict: [-0.11597285162303123]  true: [-0.11283942307398542]\n",
      "[0.3266449 0.5270581] -> predict: [0.46515278407160104]  true: [0.46290925040053493]\n",
      "[0.8859421  0.35726976] -> predict: [0.9999999900739792]  true: [1.471643388963662]\n",
      "[0.90853515 0.62336012] -> predict: [0.9999971452966877]  true: [1.2394426105878962]\n",
      "[0.01582124 0.92943723] -> predict: [-0.41503289015980027]  true: [-0.4057053694739269]\n",
      "[0.69089692 0.99732285] -> predict: [0.5383866339757792]  true: [0.5390225258239053]\n",
      "[0.17234051 0.13713575] -> predict: [0.619663796452679]  true: [0.6213750128891151]\n",
      "[0.93259546 0.69681816] -> predict: [0.9999864712922958]  true: [1.2020750330658454]\n",
      "[0.06600017 0.75546305] -> predict: [-0.15865871704262066]  true: [-0.15646279351937264]\n",
      "[0.75387619 0.92302454] -> predict: [0.702575498780912]  true: [0.7077897471453861]\n",
      "[0.71152476 0.12427096] -> predict: [0.9999999860405708]  true: [1.4430161759705429]\n",
      "[0.01988013 0.02621099] -> predict: [0.5067762614604919]  true: [0.5036092138819741]\n",
      "[0.02830649 0.24621107] -> predict: [0.296531624088966]  true: [0.296248664428146]\n",
      "[0.86002795 0.53883106] -> predict: [0.9999981865469876]  true: [1.2512108586826791]\n",
      "[0.55282198 0.84203089] -> predict: [0.4882231057074229]  true: [0.48720207566904306]\n",
      "[0.12417332 0.27918368] -> predict: [0.40989936576956765]  true: [0.4070762936687272]\n",
      "[0.58575927 0.96959575] -> predict: [0.40994492738968036]  true: [0.40904315886775733]\n",
      "[0.56103022 0.01864729] -> predict: [0.9999998342654429]  true: [1.3228980395106218]\n",
      "[0.80063267 0.23297427] -> predict: [0.9999999896293591]  true: [1.467974735179904]\n",
      "[0.8071052  0.38786064] -> predict: [0.9999998423764621]  true: [1.3227971493639972]\n",
      "[0.86354185 0.74712164] -> predict: [0.9946701905876232]  true: [1.0481911391019585]\n",
      "[0.55624023 0.13645523] -> predict: [0.9999817315148833]  true: [1.1979051253249433]\n",
      "[0.05991769 0.12134346] -> predict: [0.4719486759816952]  true: [0.46853307852758014]\n",
      "[0.04455188 0.10749413] -> predict: [0.4628531847283578]  true: [0.4593336887110497]\n",
      "[0.22570934 0.71298898] -> predict: [0.12177180456902081]  true: [0.12557502752910538]\n",
      "[0.55971698 0.01255598] -> predict: [0.9999998528406651]  true: [1.3270194929220978]\n",
      "[0.07197428 0.96727633] -> predict: [-0.3651996388524397]  true: [-0.3593149104660418]\n",
      "[0.56810046 0.20329323] -> predict: [0.9998511555733942]  true: [1.1488574582189228]\n",
      "[0.25232574 0.74382585] -> predict: [0.1309552771595203]  true: [0.1346627627803922]\n",
      "[0.19542948 0.58135893] -> predict: [0.20929193097822626]  true: [0.2117852943907204]\n",
      "[0.97001999 0.8468288 ] -> predict: [0.9993232374410113]  true: [1.1082011821424333]\n",
      "[0.23984776 0.49376971] -> predict: [0.367580165745469]  true: [0.3660019244526493]\n",
      "[0.61995572 0.8289809 ] -> predict: [0.5985382332843121]  true: [0.6009526780218909]\n",
      "[0.15679139 0.0185762 ] -> predict: [0.7119223589417213]  true: [0.7166108897917169]\n",
      "[0.07002214 0.48634511] -> predict: [0.11460520312600021]  true: [0.11868810464180168]\n",
      "[0.60632946 0.56885144] -> predict: [0.8438344672839401]  true: [0.8406427553935142]\n",
      "[0.31736241 0.98861615] -> predict: [-0.015017262403064668]  true: [-0.012572540429207746]\n",
      "[0.57974522 0.38014117] -> predict: [0.9760221652761613]  true: [0.9894766562451449]\n",
      "[0.55094822 0.74533443] -> predict: [0.5796717259824063]  true: [0.5810878977703432]\n",
      "[0.66923289 0.26491956] -> predict: [0.9999968661475588]  true: [1.2389297825169676]\n",
      "[0.06633483 0.3700842 ] -> predict: [0.2275259916796885]  true: [0.22941805372855606]\n",
      "[0.62971751 0.21017401] -> predict: [0.9999961841449359]  true: [1.234402250617507]\n",
      "[0.75275555 0.06653648] -> predict: [0.9999999947820462]  true: [1.5625968492541058]\n",
      "[0.2603151  0.80475456] -> predict: [0.08190388809565843]  true: [0.08571808412446602]\n",
      "[0.19343428 0.63946088] -> predict: [0.14709304580505786]  true: [0.15069054305505147]\n",
      "[0.52467031 0.92480797] -> predict: [0.3626218617195267]  true: [0.36219749328624984]\n",
      "[0.26329677 0.06596109] -> predict: [0.829745886876694]  true: [0.8289840650466427]\n",
      "[0.73506596 0.77217803] -> predict: [0.8330221063055954]  true: [0.8304209153897575]\n",
      "[0.90781585 0.93197207] -> predict: [0.9366743500991079]  true: [0.9297517095584488]\n",
      "[0.01395157 0.23436209] -> predict: [0.28656691208169544]  true: [0.286565273341975]\n",
      "[0.61677836 0.94901632] -> predict: [0.4769986421378957]  true: [0.47615121481487]\n"
     ]
    }
   ],
   "source": [
    "# Tranning data\n",
    "data = [[[2,-1],[0.01]]]\n",
    "\n",
    "# create a network with two input, two hidden, and one output nodes\n",
    "n = NN(2, 3, 1)\n",
    "n.weights()\n",
    "# train it with some patterns\n",
    "n.train(learnData,10000,0.6)\n",
    "n.weights()\n",
    "# test it\n",
    "pred=n.test(learnData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input weights:\n",
      "[0.7752611519361811, 4.83466508958236, 1.7725950889873079]\n",
      "[0.30624297837870496, -3.2365057836282607, -1.2821500512928392]\n",
      "[2.316651825323105, -2.444098864565266, 0.4517646935549131]\n",
      "\n",
      "Output weights:\n",
      "[4.5206576807136525]\n",
      "[4.297282458593665]\n",
      "[0.8289972595795668]\n"
     ]
    }
   ],
   "source": [
    "# 學習後的權重\n",
    "n.weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.531590104135168"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(0.64566*0.4+0.66819*0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(X[:,0], Y, s=10, label='True')\n",
    "plt.scatter(X[:,0], pred, color=\"r\",s=10, label='Predicted')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4067780526907143 0.40520851361170285\n",
      "0.19514664624715128 0.19783898959417756\n",
      "0.6258781121680521 0.6277952414568717\n",
      "0.4366660145868872 0.4338295900234586\n",
      "0.5564230365760745 0.556334477342648\n",
      "0.4454206545695186 0.44357227120818277\n",
      "-0.07350188134698929 -0.07143906179366932\n",
      "-0.1321526110488855 -0.12938612038151298\n",
      "0.5668885476341313 0.5672673751049387\n",
      "0.5149265170246144 0.5124789188079719\n",
      "0.7280783582524261 0.7328552772939074\n",
      "0.27682069268393505 0.2778136515695502\n",
      "0.9278111215908333 0.91997706494021\n",
      "0.5885889933281986 0.5885115338217846\n",
      "-0.12491392345709867 -0.12339687408255973\n",
      "0.224395463341069 0.22641262574452298\n",
      "0.9999999755983042 1.4036690102527358\n",
      "0.9999938144349155 1.222300039919647\n",
      "0.6899843907935512 0.6951257196250026\n",
      "-0.22553835757622756 -0.22271189892867982\n",
      "0.9999966810518478 1.2351259789799027\n",
      "0.12768806820154702 0.13138665964511925\n",
      "0.2044147032307634 0.20694548369055787\n",
      "0.9999999949636958 1.569279106265964\n",
      "0.8001044662412385 0.8016344357612455\n",
      "-0.15249011301313947 -0.14978509613444535\n",
      "0.552912075396171 0.5518955146278623\n",
      "0.9999659930802829 1.183997193803427\n",
      "0.9999910560625717 1.2144478333322093\n",
      "0.6793244166167595 0.6841999453339952\n",
      "0.23778977681738486 0.23944565542217044\n",
      "0.9996548706572921 1.127420967064715\n",
      "0.0347171519285619 0.03903378250361916\n",
      "0.9718284095139735 0.9808028557713746\n",
      "0.9999998762537443 1.3303370934842271\n",
      "0.9999999965633564 1.7176281687855877\n",
      "-0.10061228102142154 -0.09847676783338599\n",
      "0.9353485895059392 0.9311610583613676\n",
      "0.9999999942736018 1.5434970108485442\n",
      "0.9081878981590502 0.9002201693537819\n",
      "0.9999857826784111 1.201286929753106\n",
      "0.9999993042528379 1.2775153090631632\n",
      "0.005946673460153003 0.009005619451472269\n",
      "0.17408010979361963 0.1772967376585568\n",
      "0.8799272836548174 0.8734665265185504\n",
      "-0.27976808685044185 -0.2773702992770084\n",
      "0.5948563194583002 0.596478585832779\n",
      "0.8805129653515533 0.875178223898894\n",
      "0.9999994177881673 1.2813897941710948\n",
      "-0.11597285162303123 -0.11283942307398542\n",
      "0.46515278407160104 0.46290925040053493\n",
      "0.9999999900739792 1.471643388963662\n",
      "0.9999971452966877 1.2394426105878962\n",
      "-0.41503289015980027 -0.4057053694739269\n",
      "0.5383866339757792 0.5390225258239053\n",
      "0.619663796452679 0.6213750128891151\n",
      "0.9999864712922958 1.2020750330658454\n",
      "-0.15865871704262066 -0.15646279351937264\n",
      "0.702575498780912 0.7077897471453861\n",
      "0.9999999860405708 1.4430161759705429\n",
      "0.5067762614604919 0.5036092138819741\n",
      "0.296531624088966 0.296248664428146\n",
      "0.9999981865469876 1.2512108586826791\n",
      "0.4882231057074229 0.48720207566904306\n",
      "0.40989936576956765 0.4070762936687272\n",
      "0.40994492738968036 0.40904315886775733\n",
      "0.9999998342654429 1.3228980395106218\n",
      "0.9999999896293591 1.467974735179904\n",
      "0.9999998423764621 1.3227971493639972\n",
      "0.9946701905876232 1.0481911391019585\n",
      "0.9999817315148833 1.1979051253249433\n",
      "0.4719486759816952 0.46853307852758014\n",
      "0.4628531847283578 0.4593336887110497\n",
      "0.12177180456902081 0.12557502752910538\n",
      "0.9999998528406651 1.3270194929220978\n",
      "-0.3651996388524397 -0.3593149104660418\n",
      "0.9998511555733942 1.1488574582189228\n",
      "0.1309552771595203 0.1346627627803922\n",
      "0.20929193097822626 0.2117852943907204\n",
      "0.9993232374410113 1.1082011821424333\n",
      "0.367580165745469 0.3660019244526493\n",
      "0.5985382332843121 0.6009526780218909\n",
      "0.7119223589417213 0.7166108897917169\n",
      "0.11460520312600021 0.11868810464180168\n",
      "0.8438344672839401 0.8406427553935142\n",
      "-0.015017262403064668 -0.012572540429207746\n",
      "0.9760221652761613 0.9894766562451449\n",
      "0.5796717259824063 0.5810878977703432\n",
      "0.9999968661475588 1.2389297825169676\n",
      "0.2275259916796885 0.22941805372855606\n",
      "0.9999961841449359 1.234402250617507\n",
      "0.9999999947820462 1.5625968492541058\n",
      "0.08190388809565843 0.08571808412446602\n",
      "0.14709304580505786 0.15069054305505147\n",
      "0.3626218617195267 0.36219749328624984\n",
      "0.829745886876694 0.8289840650466427\n",
      "0.8330221063055954 0.8304209153897575\n",
      "0.9366743500991079 0.9297517095584488\n",
      "0.28656691208169544 0.286565273341975\n",
      "0.4769986421378957 0.47615121481487\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    print(pred[i],Y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
